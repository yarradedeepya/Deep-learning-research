{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4beb18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 360 images belonging to 45 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an instance of the ImageDataGenerator class with the desired parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Generate batches of images from a folder\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    './MMU-Iris-Database',\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=128,\n",
    "    class_mode='input',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Get a batch of images\n",
    "batch_images, _ = next(train_generator)\n",
    "\n",
    "# Reshape the images array to the desired shape\n",
    "images = batch_images.reshape((-1, 28, 28, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7dee812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890d9f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "r (30, 28, 28, 1)\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "f (30, 28, 28, 1)\n",
      "x-shape (60, 28, 28, 1)\n",
      "y-shape (60, 1)\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_train_function.<locals>.train_function at 0x0000022DE2D9F160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/1, Batch 0/4, D_loss: 0.681, D_acc: 63.33%, G_loss: 0.737\n",
      "r (30, 28, 28, 1)\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "f (30, 28, 28, 1)\n",
      "x-shape (60, 28, 28, 1)\n",
      "y-shape (60, 1)\n",
      "Epoch 1/1, Batch 1/4, D_loss: 0.665, D_acc: 45.00%, G_loss: 0.699\n",
      "r (30, 28, 28, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "f (30, 28, 28, 1)\n",
      "x-shape (60, 28, 28, 1)\n",
      "y-shape (60, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_images = images\n",
    "\n",
    "\n",
    "# Normalize the images to [-1, 1]\n",
    "train_images = (train_images.astype('float32') - 127.5) / 127.5\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "\n",
    "\n",
    "# Set the dimensions of the generator's input noise\n",
    "latent_dim = 100\n",
    "\n",
    "mobilenet = MobileNetV2(include_top=False)\n",
    "\n",
    "# Freeze the layers of the MobileNet model\n",
    "for layer in mobilenet.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Define the generator model\n",
    "generator = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(7*7*256, input_dim=latent_dim),\n",
    "    tf.keras.layers.Reshape((7, 7, 256)),\n",
    "    tf.keras.layers.Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2DTranspose(64, (3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2DTranspose(1, (3,3), strides=(2,2), padding='same', activation='tanh')\n",
    "])\n",
    "\n",
    "# Define the discriminator model\n",
    "discriminator = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), strides=(2,2), padding='same', input_shape=[28, 28, 1]),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), padding='same'),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Compile the discriminator\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "\n",
    "gan_input = tf.keras.Input(shape=(latent_dim,))\n",
    "gan_output = generator(gan_input)\n",
    "gan_output_resized = tf.image.resize(gan_output, (224, 224))\n",
    "gan_output_resized = tf.keras.layers.Lambda(lambda x: tf.repeat(x, 3, axis=-1))(gan_output_resized)\n",
    "gan_output = mobilenet(gan_output_resized)\n",
    "gan_output_resized = tf.image.resize(gan_output, (28, 28))\n",
    "gan_output_resized = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x[:,:,:,0], axis=-1))(gan_output_resized)\n",
    "gan_output = discriminator(gan_output_resized)\n",
    "gan = tf.keras.Model(gan_input, gan_output) \n",
    "\n",
    "# Combine the generator and discriminator into a single model\n",
    "#gan = tf.keras.Sequential([generator, discriminator])\n",
    "\n",
    "# Compile the GAN model\n",
    "gan.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5))\n",
    "\n",
    "# Define a function to generate fake images\n",
    "def generate_images(generator_model, epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, latent_dim])\n",
    "    generated_images = generator_model.predict(noise)\n",
    "    generated_images = generated_images * 0.5 + 0.5\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"gan_mnist_epoch{epoch}.png\")\n",
    "\n",
    "# Define the training loop\n",
    "def train(epochs, batch_size=128, save_interval=50):\n",
    "    # Calculate the number of batches per epoch\n",
    "    batch_count = train_images.shape[0] // batch_size\n",
    "\n",
    "    # Train the model for the specified number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(batch_count):\n",
    "            # Get a batch of real images\n",
    "            real_images = train_images[np.random.randint(0, train_images.shape[0], size=batch_size)].squeeze(axis=-1)\n",
    "            print(\"r\",real_images.shape)\n",
    "\n",
    "            # Generate a batch of fake images\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, latent_dim])\n",
    "            fake_images = generator.predict(noise)\n",
    "            print(\"f\",fake_images.shape)\n",
    "            \n",
    "            # Concatenate the real and fake images into a single batch\n",
    "            x = np.concatenate((real_images, fake_images))\n",
    "\n",
    "            # Create the labels for the discriminator\n",
    "            y = np.ones([2*batch_size, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "\n",
    "            # Train the discriminator on this batch of images\n",
    "            print(\"x-shape\",x.shape)\n",
    "            print(\"y-shape\",y.shape)\n",
    "            d_loss, d_acc = discriminator.train_on_batch(x, y)\n",
    "\n",
    "            # Train the generator by fooling the discriminator\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, latent_dim])\n",
    "            y = np.ones([batch_size, 1])\n",
    "            g_loss = gan.train_on_batch(noise, y)\n",
    "            # Print the progress\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Batch {batch}/{batch_count}, D_loss: {d_loss:.3f}, D_acc: {d_acc*100:.2f}%, G_loss: {g_loss:.3f}\")\n",
    "\n",
    "        # Save the generated images every save_interval epochs\n",
    "        if epoch % save_interval == 0:\n",
    "            generate_images(generator, epoch)\n",
    "\n",
    "    # Save the final generator model\n",
    "    generator.save(\"mnist_gan_generator.h5\")\n",
    "    \n",
    "def predicttest(test_images):\n",
    "    \n",
    "    # Get a batch of real images\n",
    "    real_images = test_images[:100]\n",
    "\n",
    "    # Generate a batch of fake images\n",
    "    noise = np.random.normal(0, 1, size=[100, 100])\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    # Use the discriminator to predict whether each image is real or fake\n",
    "    real_labels = np.ones((100, 1))\n",
    "    fake_labels = np.zeros((100, 1))\n",
    "    discriminator_labels = np.vstack([real_labels, fake_labels])\n",
    "    images=np.vstack([real_images, generated_images])\n",
    "    discriminator_predictions = discriminator.predict(images)\n",
    "\n",
    "    # Evaluate the discriminator's performance\n",
    "    accuracy = np.mean((discriminator_predictions > 0.5) == discriminator_labels)\n",
    "    print(f\"Discriminator accuracy: {accuracy}\")\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(\"Prediction: {}\".format(discriminator_predictions[i]))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainmodel= train(1, batch_size=30, save_interval=50)\n",
    "# Load the MNIST dataset\n",
    "test_images = images\n",
    "# Normalize the test images to [-1, 1]\n",
    "test_images = (test_images.astype('float32') - 127.5) / 127.5\n",
    "#test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "predicttest(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da035be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "accu=[]\n",
    "model = load_model('mnist_gan_generator.h5')\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "def white_box_attack(x_test, y_test, generator, discriminator, epsilon=0.1):\n",
    "    x_adv = np.zeros_like(x_test)\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        # Generate adversarial example\n",
    "        print(\"test no\",i,\"/\",len(x_test))\n",
    "        x = x_test[i]\n",
    "        y_true = y_test[i]\n",
    "        y_test_i = np.expand_dims(y_test[i], axis=0)\n",
    "        noise = np.random.normal(0, 1, (1, 100))\n",
    "        generated_image = generator.predict(noise)\n",
    "        d_loss, d_acc = discriminator.evaluate(x.reshape(1, 28, 28, 1))\n",
    "        g_loss, g_acc = discriminator.evaluate(generated_image)\n",
    "        if g_acc > d_acc:\n",
    "            # If the generator is more accurate than the discriminator, add perturbation\n",
    "            print(\"generator is more accurate than discriminator\")\n",
    "            perturbation = np.sign(generator.gradient(noise, y_true)) * epsilon\n",
    "            x_adv[i] = np.clip(generated_image + perturbation, 0, 1)\n",
    "           \n",
    "        else:\n",
    "            \n",
    "            x_adv[i] = generated_image\n",
    "            x_adv_i = np.expand_dims(x_adv[i], axis=0)\n",
    "            x_adv_i  =x_adv_i.reshape((1, 28*28))\n",
    "            x_adv_i = x_adv_i[:,:100]\n",
    "            print(\"x_adv[i]\",x_adv_i.shape)\n",
    "            #y_test_i = np.squeeze(np.reshape(y_test, (-1, 28, 28, 1)))\n",
    "            print(\"y_test[i]\",y_test[i].shape)\n",
    "            \n",
    "            #y_test_i = np.squeeze(y_test[i], axis=0)\n",
    "            #y_test_i = np.reshape(y_test_i, (-1, 28, 28, 1))\n",
    "            \n",
    "      \n",
    "        loss, acc = model.evaluate(x_adv_i, y_test_i)\n",
    "        print('Target model accuracy on the adversarial examples:', acc)\n",
    "        accu.append(acc)\n",
    "        print(acc)\n",
    "         \n",
    "\n",
    "    return accu\n",
    "\n",
    "\n",
    "x_test = images\n",
    "y_test = images\n",
    "\n",
    "accur=white_box_attack(x_test, y_test, generator, discriminator, epsilon=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d8e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x= list(range(0,len(accur)))\n",
    "\n",
    "plt.plot(x, accur)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165df84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the MNIST dataset\n",
    "x_test = images\n",
    "y_test= images\n",
    "#\n",
    "accu=[]\n",
    "# Preprocess the data\n",
    "x_test = x_test[:784].astype('float32') / 255.\n",
    "y_test = x_test[:784].astype('float32') / 255.\n",
    "print(\"shape\", y_test.shape)\n",
    "# Load the target model (black box)\n",
    "model = load_model('mnist_gan_generator.h5')\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Define the black box attack function\n",
    "def black_box_attack(x_test, y_test, model):\n",
    "    epsilon = 0.1  # Perturbation size\n",
    "    #x_adv = np.zeros_like(28,28)\n",
    "    x_adv = np.empty((10000, 1, 100))\n",
    "\n",
    "\n",
    "\n",
    "    print(\"xtest shape\",x_test.shape)\n",
    "    print(\"x_adv shape\",x_adv.shape)\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        print(\"x_test no:\",i,\"/\",len(x_test))\n",
    "        # Generate adversarial example\n",
    "        x = x_test[i]\n",
    "        y_true = y_test[i]\n",
    "        noise = np.random.normal(0, 1, (1, 100))\n",
    "        \n",
    "        print(\"noise shape\",noise.shape)\n",
    "        generated_image = model.predict(noise)\n",
    "        print(\"generated_image shape\",generated_image.shape)\n",
    "        generated_image = generated_image.reshape((1, 28*28))\n",
    "        generated_image = generated_image[:,:100]\n",
    "        print(\"updated generated_image shape\",generated_image.shape)\n",
    "        #generated_image = generated_image.reshape((28, 28, 1)) # reshape to match the input shape of the target model\n",
    "        generated_image = np.clip(generated_image, 0, 1) # clip the values to [0, 1]\n",
    "        test=model.predict(generated_image)\n",
    "        y_pred_label = np.argmax(test)\n",
    "        y_test = np.reshape(y_test[:784], (-1, 28, 28, 1))\n",
    "        print(\"xyz\",y_test[i][np.newaxis, ...].shape)\n",
    "        if y_pred_label == np.argmax(y_true):\n",
    "            # If the prediction is correct, add perturbation\n",
    "            print(\"prediction is correct\")\n",
    "            #perturbation = np.sign(model.gradient(np.array([generated_image]), np.array([y_true]))) * epsilon\n",
    "            #x_adv[i] = np.clip(generated_image + perturbation, 0, 1)\n",
    "            \n",
    "            with tf.GradientTape() as tape:\n",
    "                generated_image_tensor = tf.convert_to_tensor(generated_image)\n",
    "                tape.watch(generated_image_tensor)\n",
    "                print(generated_image_tensor.shape)\n",
    "                #generated_image_tensor= generated_image_tensor.numpy().reshape((1, 28*28))\n",
    "                #generated_image_tensor =tf.convert_to_tensor(generated_image_tensor[:,:100])\n",
    "                tape.watch(generated_image_tensor)\n",
    "                y_pred = model(generated_image_tensor)\n",
    "                y_true = tf.expand_dims(y_true, axis=0) # add an extra dimension to match the shape of y_pred\n",
    "                #y_true=tf.expand_dims(y_true, axis=-1)\n",
    "                loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "                #print(\"loss\",loss)\n",
    "                #print(\"gradient\", tf.convert_to_tensor(generated_image_tensor))\n",
    "            gradients = tape.gradient(loss, generated_image_tensor)\n",
    "            #print(\"gradient\", gradients)\n",
    "            perturbation = 0.01 * tf.sign(gradients)\n",
    "            generated_image = generated_image + perturbation.numpy()\n",
    "            x_adv[i]= generated_image\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print(\"prediction is not correct\")\n",
    "            print(\"generated_image shape\",generated_image.shape)\n",
    "            print(\"x_adv shape\",x_adv.shape)\n",
    "            x_adv[i] = generated_image\n",
    "            print(\"abc\",x_adv[i].shape)\n",
    "            \n",
    "        loss, acc = model.evaluate(x_adv[i], y_test[i][np.newaxis, ...])\n",
    "        print('Target model accuracy on the adversarial examples:', acc)\n",
    "        accu.append(acc)\n",
    "            \n",
    "    return accu\n",
    "\n",
    "#print(\"xtestshape\",x_test.shape)\n",
    "#print(\"y_test\",y_test.shape)\n",
    "# Generate the adversarial examples\n",
    "accur= black_box_attack(x_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af22aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x= list(range(0,len(accur)))\n",
    "\n",
    "plt.plot(x, accur)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d612ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492047c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88277c35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
